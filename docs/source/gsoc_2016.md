Summer of Code 2016
=====================

Our Vision and Goal
--------------------

We are witnessing a proliferation of massive visual data. Unfortunately scaling existing computer vision algorithms to large datasets leaves researchers repeatedly solving the same algorithmic and infrastructural problems. 

Our goal is to democratize computer vision; one should not have to be a computer vision, deep learning, and distributed computing expert to have access to state-of-the-art distributed computer vision algorithms. We provide access to state-of-art distributed computer vision algorithms as a cloud service through Web Interface & APIs. Researchers, Students and Developers will be able to access these distributed computer vision algorithms and the computation power through small number of clicks and minimal lines of code. 

A recent World Economic Form report and a New York Times article declared data to be a new class of economic asset, like currency or gold. Visual content is arguably the fastest growing data on the web. Photo-sharing websites like Flickr and Facebook now host more than 6 and 90 Billion photos (respectively). Besides consumer data, diverse scientific communities (Civil & Aerospace Engineering, Computational Biology, Bioinformatics, and Astrophysics, etc) are also beginning to generate massive archives of visual content, without necessarily the expertise or tools to analyze them.

We are building CloudCV, an ambitious system that will provide access to state-of-the-art distributed computer vision algorithms on the cloud, as a service to the community. CloudCV will contain algorithms for end-to-end processing of image & video content: from low-level filtering and data processing to high-level tasks like face detection, person detection, object detection, tracking, action and intent detection, etc.

Challenge
-----------

Designing and implementing efficient and provably correct parallel computer vision algorithms is extremely challenging. Some tasks like extracting statistics from image collections are embarrassingly parallel, i.e. can be parallelized simply by distributing the images to different machines. This is where framework such as MapReduce have demonstrated success. Unfortunately, most tasks in computer vision and machine learning such as training a face detector are not embarrassingly parallel – there are data and computational dependencies between images and various steps in the algorithm. Moreover, for each such parallel algorithm, researchers must repeatedly solve the same low-level problems: building & maintaining a cluster of machines, formulating parallelizable components in computer vision algorithms, designing multi-threaded primitives, writing custom hardware wrappers, implementing mechanisms to avoid race-conditions, dead-locks, etc.

Current status as of February 2016
------------------------------------

Data Sharing
^^^^^^^^^^^^^

We have released 16 "industry standard" pre-computed features for all 1.2 million images in the ImageNet Challenge [7], as a resource that others in the community can build on.Web Services and Demos: cloudcv.org hosts the following services:

**Image Classification**: A Convolutional Neural Network (CNN) based image auto-tagging web-service. Allows a user to upload an image. Outputs names of categories present in the image. 

**Training a New Category**: Giving a user the capability to train a visual classifier for a new user-defined category (not already present in the model). User is able to provide training examples for each of these new categories, and test against an updated CNN. 

**Visual Question Answering**: A web-service where a user may upload any image, and ask any free-form natural language question about the image (“How many people are in this image?”,  “What are the people doing?”) and receive a natural language answer back (“5”, “playing frisbee”). 

Python APIs
^^^^^^^^^^^^^

We have released Python APIs that allow users to "call" CloudCV web-services and functions. In all cases, the images are sent to our servers at Virginia Tech and EC2 instances, and and results of the executables are made available to the users' running Python and Matlab instances when ready.
All demos utilize the Caffe Deep Learning framework, and run on NVIDIA Tesla K40s, courtesy of the NVIDIA Academic Hardware Donation Program (NVIDIA contact: Stephen Jones).
Beta Features
Dockerized version of CloudCV to make CloudCV more portable and easier to install on AWS instances or in-house servers. 
A user-authentication system that allows the user to sign-up on CloudCV with Google / Dropbox authentication and allows them to upload images from Dropbox / Google Drive. This allows them to run jobs on large number of images without worrying about having to stay connected with the CloudCV servers. 

GSOC 2016 Ideas
-----------------

1: CloudCV-fy your vision/deep-learning code
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Deep learning and its application in AI-subfields (computer vision, natural language processing) has seen a tremendous growth in the recent years. Driven in part by code, data, and manuscript sharing on github and arxiv, we are witnessing increasing public access to state-of-the-art deep learning models for object detection, classification, image captioning, and visual question answering. 

However, running someone’s released implementation and making sense of the results often involves painstaking preparation and execution involving steps like setting up the environment and dependencies (installing torch / caffe / tensorflow / keras / theano), setting up the I/O pipeline, keeping track of inter-package consistencies, etc. 

We want to build a system that can automatically “**CloudCV-fy the code**” and create an online demo and a corresponding API that other researchers / developers can use without understanding fine-grained details about how the algorithm works. Testing or experimenting the model should be as simple as going to a web-page and uploading images to look at the results. 
Examples of such manually curated demos can be found at:
 
 - http://cloudcv.org/vqa/
 - http://cloudcv.org/classify/
 - http://cloudcv.org/vip/

There are many ways to do this and the students will be expected to perform a feasibility study to determine the best way to achieve this goal. 
Here are some ideas:
 
 **Goal:**

   **Input**: the path to a github page with some demo code.

   **Output**: create http://cloudcv.org/username/demo_name
 
 Automatically create a pull request on the github repository that contains the wrappers around the code. This pull request can contain code to run a web-server, and docker containers so that setting up the demo online is as simple as pulling this branch and running a command or a bash script. 
 
 CloudCV should be able to host some of these more popular models on their own - server. Users can either decide to create their own profile and upload such a model or we should be able to do it automatically for open-source contributions. 

**[Stretch goal]** Building Python and Lua APIs so that anybody can use these models available publically in their own machinery through API hooks.

**Difficulty**: Difficult (Almost at the verge of being ambitious)

Pre-requisites
***************

 - Familiarity with Docker containers, javascript and bash scripts. 
 - Expertise in using python based web-servers like Flask and Django. 
 - Familiarity with deep learning frameworks like Caffe / Theano / Keras / TensorFlow etc. 
 - Students are expected to have played around with these tools and should be familiar with the input / output pipelines.
 - Familiarity with building multi-threading, multi-processing architectures, and asynchronous operations. 
 - Expertise in Lua (especially Torch framework) to build a similar tool for Torch. This may require building an interface for python-torch communication and the student will have to experiment with various ways since Lua is not as mature as Python in terms of open source web-frameworks.

**Number of Students:** 2

2: Build Deep Learning models online
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

**Difficulty**: Difficult 

One of the other problems facing young researchers who want to learn more about deep learning models is the amount of effort it takes to learn these new frameworks. Here is a small list of 64 deep learning frameworks that are available. Each framework is good at different purposes. The goal of this project is to provide an online platform for trying deep learning algorithms / models that will reduce the barrier of entry to the world of deep learning and applications in computer vision. We want to build a “drag-and-drop” interface which will consist of various modules like Convolution, Max-Pool, ReLU, LSTM unit, Soft-Max unit that will allow users to plug together a system for training/testing their deep learning model. This allow for rapid, interactive experience without having to worry about setting up infrastructure. 

Pre-requisites
***************

 - Expertise in Javascript and familiarity with existing frameworks that can help building this online tool.
 - Expertise in using python based web-servers like Flask. 
 - Expertise with deep learning models and algorithms. Familiarity with deep learning frameworks like Caffe / Theano / Keras / TensorFlow etc.
 - Students are expected to have played around with these tools and should be familiar with the input / output pipelines.

**Number of Students:** 1

3: Writing tutorials and implementing popular deep learning architectures in CloudCV
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

This project is aimed at students who are looking for a more research-oriented experience during CloudCV GSoC. This will involve reading and implementing popular deep learning papers and integrating them with CloudCV. This project will complement the other two projects such that at the end of summers we have a few example architecture already CloudCV-fied. This will also help us identifying potential caveats in building a CloudCV-fy your code like system.

The student will also be responsible for building an interface where users can share their code and write a corresponding tutorial. The page will essentially be a one stop resource from finding relevant papers, their open source code, an online demo to showcase the capability and short tutorial.

**Difficulty:** Medium

Some Relevant Resource:

 - http://gitxiv.com/
 - https://github.com/ChristosChristofidis/awesome-deep-learning
 - https://github.com/kjw0612/awesome-deep-vision
 - http://meta-guide.com/software-meta-guide/100-best-github-deep-learning

Pre-requisites
***************

 - Expertise in Javascript and familiarity with existing frameworks that can help building this online tool.
 - Expertise with deep learning models and algorithms. Familiarity with deep learning frameworks like Caffe / Theano / Keras / TensorFlow etc. Students are expected to have played around with these tools

**Number of Students**: 1

Tasks for Students participating in GSOC 2016
-----------------------------------------------

To make sure that we have a lot of interesting things to talk about during the application process, we have designed some toy tasks for you that you will hopefully find exciting and somewhat challenging.

To put things in perspective as to why are we giving these toy-tasks and what are our motivations behind this. We like to prototype quickly (in a very hacky way). It often involves integrating a bunch of technologies / libraries to get stuff done. None of us in the team will call ourselves expert of a particular technology but often just knowing the bare minimum to figure out the puzzle is sufficient. Also most of you are new contributors to CloudCV, therefore instead of trying to learn our code-base it would be best if everyone tries to do a task that is relevant to the three main project ideas. These tasks are very similar to the kind of things CloudCV team does and if you get a kick out of doing these tasks then we can promise that the summer will be a lot of fun and will be an amazing learning experience. It also acts as a good way for us to evaluate all the proposals fairly. Everybody will have the same time to complete a task, everybody will work on the same task and progress on this task is a good indicator of the skill set. We will typically look at the progress on this task and will “design” ramp-up courses for the selected students before the coding period so that they are familiar with the relevant technologies to start working on the major project idea.

TOY-TASK #1
^^^^^^^^^^^^

We hope you have tried the http://cloudcv.org/vqa/

The first task is to build a similar demo. The task is fairly open ended and you are only required to do the bare minimum of setting up simple webpage that accepts an image and a question and generates an answer. This can feel intimidating at first and that is where we come into the picture. The mentors are there to help you along the way and feel free to ask us any questions. At the very least, the next few weeks will be learning experience for all of us.

Here are more details about the first task:

1. Train a VQA model using a subset of VQA dataset (feel free to train on the entire dataset if you have enough computational resources). Here is an awesome resource that might be helpful:

 - http://avisingh599.github.io/deeplearning/visual-qa/ (Implemented in Keras, might be the easiest to start with)
 - https://github.com/abhshkdz/neural-vqa
 - https://github.com/VT-vision-lab/VQA_LSTM_CNN (These two are torch based models, might be a bit difficult if you are not already familiar with Torch)

2. Build a web demo that takes as input an image, and question and uses the VQA model you trained to predict answers. So this will require you to build a full end-to-end system, that will take an image and a question through a web interface, send it to a server , process the image ( extract features, send it through the VQA pipeline, get predictions) and finally display the top-k predictions on the webpage.

3. We understand that hosting the server can be a problem, so as long as you share with us a video of the server running locally, we are fine.

Again, we will happy to have a chat or discuss over email if you need help / directions in case you get stuck. There are obviously some missing details which we can answer on the forum or on the gitter channel.

If I were you, I would proudly blog about the process/various hacks that I tried to get it running for other people to see. :-)

Looking forward to all the cool things you people do.


TOY-TASK #2
^^^^^^^^^^^^

We will be uploading the details about the task 2 very soon.

----------

**Disclaimer:** It’s okey if you are not an expert but are willing to learn. We will be releasing a couple of toy tasks to make you familiar with the relevant technologies so feel free to ping us about your doubts. 

Do you have doubts, ask us on gitter at https://gitter.im/batra-mlp-lab/CloudCV

----------
